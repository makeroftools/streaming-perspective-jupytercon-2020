{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "import asyncio\n",
    "import multiprocessing\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Datasources\n",
    "\n",
    "The main goal of these datasources is to ensure that Perspective is updated with new data without blocking the main thread. `BaseDataSource` implements the core of a data source that runs on a subprocess, placing returned data in a queue where it is fetched by a Perspective running in a separate thread. This allows us to spawn multiple data sources and run them all at the same time without preventing the notebook from running new cells.\n",
    "\n",
    "The IEX-based datasources we use will inherit from `BaseDataSource`, and implement datasource-specific logic. This base class handles management of subprocesses/threads, starting/stopping the datasource, and how data flows from the datasource into Perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataSource(object):\n",
    "    \n",
    "    def __init__(self, table, data_cleaner=None):\n",
    "        \"\"\"A base class for a datasource that feeds data into Perspective.\n",
    "        \n",
    "        Subclasses must implement `get_data`, which retrieves data and calls\n",
    "        `self.queue.put(data)` for Perspective to retrieve. This prevents the\n",
    "        main thread/notebook from being blocked.\n",
    "        \n",
    "        Args:\n",
    "            table (perspective.Table) a Perspective table instance that will\n",
    "                be updated with new data.\n",
    "                \n",
    "        Keyword Args:\n",
    "            data_cleaner (func) A function that receives data input and\n",
    "                returns cleaned data before the Perspective table is updated.\n",
    "        \"\"\"\n",
    "        self.table = table  # An already-created Perspective table\n",
    "        self.queue = multiprocessing.Queue()\n",
    "        self._process = multiprocessing.Process(target=self.get_data)\n",
    "        self._table_updater = threading.Thread(target=self.table_updater)\n",
    "        self._data_cleaner = data_cleaner\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"Start both the data getter subprocess and the table updater sub thread.\"\"\"\n",
    "        self._process.start()\n",
    "        self._table_updater.start()\n",
    "        logging.info(\"[DataSource] Started\")\n",
    "        \n",
    "    def stop(self):\n",
    "        \"\"\"Stop fetching data and updating Perspective.\"\"\"\n",
    "        self._process.terminate()\n",
    "        self.queue.put_nowait(\"STOP\")\n",
    "        self._table_updater.join()\n",
    "        logging.info(\"[DataSource] Stopped\")\n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"A method that gets data and submits it to `self.queue` - must be implemented\n",
    "        by the subclass.\"\"\"\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "\n",
    "    def table_updater(self):\n",
    "        \"\"\"Update the Perspective Table in a subthread, using the event loop to manage\n",
    "        the call to `update()`.\"\"\"\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        task = loop.create_task(self._update())\n",
    "        loop.run_until_complete(task)\n",
    "    \n",
    "    async def _update(self):\n",
    "        \"\"\"Update the Perspective table with data, cleaning it if necessary.\"\"\"\n",
    "        while True:\n",
    "            tick = self.queue.get()\n",
    "            if tick == \"STOP\":\n",
    "                logging.info(\"[DataSource] Stopping update thread\")\n",
    "                return True\n",
    "            elif tick:\n",
    "                if self._data_cleaner:\n",
    "                    tick = self._data_cleaner(tick)\n",
    "                self.table.update(tick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the IEX API\n",
    "\n",
    "For this tutorial, we'll be using the [IEX Cloud API](https://iexcloud.io) to provide us with streaming market data. The API provides a whole gamut of finance-related data, including live quotes, trade books, news stories, and market research, as well as foreign exchange and cryptocurrency data.\n",
    "\n",
    "In `jupytercon.ipynb`, I've set up a fictional stock portfolio of tickers and quantities, and we will use the IEX Cloud API to fetch live quotes for each symbol, as well as charting data so we can see the performance of our fictional portfolio over time. This allows us to jump into one of the main use cases for streaming data, and examine the capabilities of Perspective within a wide sandbox.\n",
    "\n",
    "To interact with the IEX Cloud API, we'll be using [pyEX](https://pyex.readthedocs.io/en/latest/), a Python interface with the IEX Cloud API that implements easy-to-use methods to get data from the IEX API. We'll be passing those methods into our datasources, calling on them to get data (either through Server-Sent Events (SSE), polling the server, or one-off requests), and passing the data into Perspective for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IEXSSEDataSource(BaseDataSource):\n",
    "    \n",
    "    def __init__(self, table, iex_source, **kwargs):\n",
    "        \"\"\"A datasource that consumes data from IEX's SSE (Server-Sent Events)\n",
    "        API, such as `pyEX.topsSSE` or `pyEX.cryptoQuotesSSE.\n",
    "        \n",
    "        Args:\n",
    "            iex_source (func) a function from pyEX that returns an SSE\n",
    "                data source, which will be called with **kwargs.\n",
    "                \n",
    "        Keyword Args:\n",
    "            kwargs (dict) keyword arguments which will be applied when calling\n",
    "                the IEX data source. See the pyEX documentation for more details.\n",
    "        \"\"\"\n",
    "        data_cleaner = kwargs.pop(\"data_cleaner\")\n",
    "        super(IEXSSEDataSource, self).__init__(table, data_cleaner=data_cleaner)\n",
    "        self._iex_source = iex_source\n",
    "        self._iex_source_kwargs = kwargs\n",
    "        \n",
    "        # Replace `on_data` kwarg with Queue.put_nowait, which\n",
    "        # will not block the process and place received data in\n",
    "        # the queue.\n",
    "        self._iex_source_kwargs[\"on_data\"] = self.queue.put_nowait\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Call the SSE datasource with the provided kwargs, placing data\n",
    "        into `self.queue`.\"\"\"\n",
    "        logging.info(\"[IEXSSEDataSource] Started\")\n",
    "        self._iex_source(**self._iex_source_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zlib import crc32\n",
    "\n",
    "def bytes_to_float(b):\n",
    "    return float(crc32(b) & 0xffffffff) / 2**32\n",
    "\n",
    "def str_to_float(s, encoding=\"utf-8\"):\n",
    "    return bytes_to_float(s.encode(encoding))\n",
    "\n",
    "class IEXIntervalDataSource(BaseDataSource):\n",
    "    \n",
    "    def __init__(self, table, iex_source, interval=1, should_hash=False, **kwargs):\n",
    "        \"\"\"A datasource that consumes data from IEX once per `interval` seconds.\n",
    "        \n",
    "        Because IEX does not provide streaming APIs for simple quotes, OHLC,\n",
    "        etc, use this datasource to query the API for updates. If `should_hash` is\n",
    "        True, the datasource will hash incoming ticks and discard duplicates.\n",
    "        \n",
    "        Args:\n",
    "            iex_source (func) a function from pyEX that returns a single piece of\n",
    "                data, such as `quote` or `batch`.\n",
    "        \n",
    "        Keyword Args:\n",
    "            kwargs (dict) keyword arguments which will be applied when calling\n",
    "                the IEX data source. See the pyEX documentation for more details.\n",
    "        \"\"\"\n",
    "        data_cleaner = kwargs.pop(\"data_cleaner\")\n",
    "        super(IEXIntervalDataSource, self).__init__(table, data_cleaner=data_cleaner)\n",
    "        self._iex_source = iex_source\n",
    "        self._iex_source_kwargs = kwargs\n",
    "        self._interval = interval\n",
    "        self._process = multiprocessing.Process(target=self.get_data)\n",
    "        \n",
    "        # Hash the dataset so it does not repeatedly enqueue identical datasets.\n",
    "        self._should_hash = should_hash\n",
    "        self._last_hash = \"\"\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Retrieve data every `interval` seconds, hashing and discarding duplicates\n",
    "        if necessary.\"\"\"\n",
    "        logging.info(\"[IEXIntervalDataSource] started: fetching every %d seconds\", self._interval)\n",
    "        def _get(self):\n",
    "            data = self._iex_source(**self._iex_source_kwargs)\n",
    "            if data:\n",
    "                if self._should_hash:\n",
    "                    hashed = str_to_float(json.dumps(data, sort_keys=True))\n",
    "                    if hashed != self._last_hash:\n",
    "                        # Only enqueue new data, not data we've already gotten.\n",
    "                        self.queue.put_nowait(data)\n",
    "                        self._last_hash = hashed\n",
    "                else:\n",
    "                    self.queue.put_nowait(data)\n",
    "            time.sleep(self._interval)\n",
    "            _get(self)\n",
    "        _get(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IEXStaticDataSource(BaseDataSource):\n",
    "    \n",
    "    def __init__(self, table, iex_source, **kwargs):\n",
    "        \"\"\"A data source for static data - calls the source once, and then stops.\n",
    "        \n",
    "        Good for non-streaming data such as charts and fundamentals.\"\"\"\n",
    "        data_cleaner = kwargs.pop(\"data_cleaner\")\n",
    "        super(IEXStaticDataSource, self).__init__(table, data_cleaner=data_cleaner)\n",
    "        self._iex_source = iex_source\n",
    "        self._iex_source_kwargs = kwargs\n",
    "    \n",
    "    def get_data(self):\n",
    "        data = self._iex_source(**self._iex_source_kwargs)\n",
    "        self.queue.put_nowait(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
