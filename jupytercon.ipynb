{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import nbimporter\n",
    "import logging\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import asyncio\n",
    "import threading\n",
    "from datetime import date, datetime\n",
    "\n",
    "# Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "\n",
    "# pyEX is an easy-to-use IEX API interface built for Python\n",
    "import pyEX\n",
    "\n",
    "# The main course\n",
    "import perspective\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Data Sources\n",
    "\n",
    "Inside `datasources.ipynb`, there are a few streaming datasources that will feed live data to Perspective. \n",
    "\n",
    "Each datasource runs on its own subprocess and subthread in order to not block the main Jupyter thread from running, so cells can still be added and evaluated as normal. In the background, the datasource will fetch data, clean it (if necessary), and update the Perspective tables—which will display the new results in each widget in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from datasources.ipynb\n"
     ]
    }
   ],
   "source": [
    "from datasources import IEXIntervalDataSource, IEXSSEDataSource, IEXStaticDataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pyEX client with the token - this is just an example sandbox token.\n",
    "token = \"Tpk_ecc89ddf30a611e9958142010a80043c\"\n",
    "client = pyEX.Client(api_token=token, version=\"sandbox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the schemas for the tables we are initializing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_schema = {\n",
    "    \"symbol\": str,\n",
    "    \"companyName\": str,\n",
    "    \"open\": float,\n",
    "    \"openTime\": datetime,\n",
    "    \"close\": float,\n",
    "    \"closeTime\": datetime,\n",
    "    \"high\": float,\n",
    "    \"highTime\": datetime,\n",
    "    \"low\": float,\n",
    "    \"lowTime\": datetime,\n",
    "    \"latestPrice\": float,\n",
    "    \"latestUpdate\": datetime,\n",
    "    \"latestVolume\": int,\n",
    "    \"volume\": int\n",
    "}\n",
    "\n",
    "last_quote_schema = {\n",
    "    \"symbol\": str,\n",
    "    \"price\": float,\n",
    "    \"time\": datetime,\n",
    "    \"size\": int,\n",
    "}\n",
    "tops_schema = {\n",
    "    \"symbol\": str,\n",
    "    \"bidSize\": int,\n",
    "    \"bidPrice\": float,\n",
    "    \"askSize\": int,\n",
    "    \"askPrice\": float,\n",
    "    \"volume\": int,\n",
    "    \"lastSalePrice\": float,\n",
    "    \"lastSaleSize\": int,\n",
    "    \"lastSaleTime\": datetime,\n",
    "    \"lastUpdated\": datetime,\n",
    "    \"sector\": str,\n",
    "    \"securityType\": str,\n",
    "    \"seq\": int\n",
    "}\n",
    "holdings_schema = {\n",
    "    \"symbol\": str,\n",
    "    \"quantity\": int,\n",
    "    \"price\": float,\n",
    "    \"time\": datetime\n",
    "}\n",
    "charts_schema = {\n",
    "    \"date\": date,\n",
    "    \"open\": float,\n",
    "    \"high\": float,\n",
    "    \"low\": float,\n",
    "    \"close\": float,\n",
    "    \"volume\": int,\n",
    "    \"symbol\": str,\n",
    "    \"quantity\": int\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Portfolio\n",
    "\n",
    "For this demonstration, let's set up a fictional portfolio of stocks—it's one of the most natural use cases for streaming data, and it provides a way for us to join static and streaming data together intuitively. In a more comprehensive example, our holdings of individual stocks will probably change over time, but we'll keep it fixed for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"SPY\", \"SNAP\", \"ZM\", \"JPM\"]\n",
    "holdings = {symbol: random.randint(5, 10) for symbol in symbols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save our portfolio, we're going to use two Perspective tables:\n",
    "\n",
    "- `holdings_table`, which is indexed on `symbol` and will always return the latest value of our portfolio based on the prices for each component.\n",
    "- `holdings_total_table`, which is not indexed, and will hold a history of prices and values for each symbol, allowing us to see the value of our portfolio over time.\n",
    "\n",
    "Using `on_update`, we link the two tables together; whenever `holdings_table` updates from the datasource, it will pass the updated rows to `holdings_total_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table from schema\n",
    "holdings_table = perspective.Table(holdings_schema, index=\"symbol\")\n",
    "\n",
    "# Update it with the symbols and quantities of each stock\n",
    "holdings_table.update({\n",
    "    \"symbol\": symbols,\n",
    "    \"quantity\": [holdings[symbol] for symbol in symbols]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the unindexed total table\n",
    "holdings_total_table = perspective.Table(holdings_schema)\n",
    "holdings_view = holdings_table.view()\n",
    "\n",
    "def update_total(port, delta):\n",
    "    \"\"\"When the indexed table updates with the latest price, update the unindexed table with the rows that changed.\"\"\"\n",
    "    holdings_total_table.update(delta)\n",
    "\n",
    "holdings_view.on_update(update_total, mode=\"row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our indexed `holdings_table`, we can create a new `PerspectiveWidget` to view the Table in Jupyterlab. Using `PerspectiveWidget`'s configuration options, we can set up the view to be exactly what we want—to show the latest price and value for our portfolio.\n",
    "\n",
    "### Computed Columns\n",
    "\n",
    "We now have the price and the quantity of each holding, but how would we calculate the value? We can do so entirely within Perspective, using the Computed Expressions UI on the widget. Using a simple, minimal expression language with syntax highlighting and type checking, we can calculate the value of each holding by multiplying the price by the quantity across each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a11ee1ad1374288bd8fa93607842b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PerspectiveWidget(aggregates={'value': 'sum not null', 'price': 'last'}, columns=['price', 'quantity', 'value'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "holdings_widget = perspective.PerspectiveWidget(\n",
    "    holdings_table,\n",
    "    aggregates={\n",
    "        \"value\": \"sum not null\",\n",
    "        \"price\": \"last\"\n",
    "    },\n",
    "    row_pivots=[\"symbol\"],\n",
    "    columns=[\"price\", \"quantity\", \"value\"],\n",
    "    sort=[[\"value\", \"desc\"]],\n",
    "    computed_columns=[{\n",
    "        \"column\": \"value\", \n",
    "        \"computed_function_name\": \"*\",\n",
    "        \"inputs\": [\"quantity\", \"price\"]\n",
    "    }]\n",
    ")\n",
    "holdings_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do the same for our `holdings_total_table`—here, we see a line chart of the portfolio value as new prices tick in, split by each symbol so we can see how the portfolio's total value is divided amongst each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6944fced778a4c05a2afc1828b79ab50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PerspectiveWidget(aggregates={'quantity': 'last', 'price': 'last'}, column_pivots=['symbol'], columns=['value'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "holdings_total_widget = perspective.PerspectiveWidget(\n",
    "    holdings_total_table,\n",
    "    plugin=\"y_line\",\n",
    "    row_pivots=[\"time\"],\n",
    "    column_pivots=[\"symbol\"],\n",
    "    aggregates={\n",
    "        \"quantity\": \"last\",\n",
    "        \"price\": \"last\"\n",
    "    },\n",
    "    columns=[\"value\"],\n",
    "    computed_columns=[{\n",
    "        \"column\": \"value\", \n",
    "        \"computed_function_name\": \"*\",\n",
    "        \"inputs\": [\"quantity\", \"price\"]\n",
    "    }]\n",
    ")\n",
    "holdings_total_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining streaming and static data sources\n",
    "\n",
    "Now that we can see our portfolio values, let's feed the real-time price of each symbol into the portfolio tables. To do this, we'll create another `Table` with\n",
    "`last_quote_schema`, which conforms to the output from IEX's [Last](https://iexcloud.io/docs/api/#last) endpoint. This API provides \"a near real time, intraday API that provides IEX last sale price, size and time,\" and is perfect for calculating the value of our portfolio quickly.\n",
    "\n",
    "We'll use `on_update` again—when `quotes_table` updates with a new quote, feed it into `holdings_table`. This will update the latest price of the symbol in our holdings, which will then (with the `on_update` callback we created earlier) feed the `holdings_total_table`. Thus, data flows from the streaming datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_table = perspective.Table(last_quote_schema)\n",
    "quotes_view = quotes_table.view()\n",
    "\n",
    "def update_holdings(port, delta):\n",
    "    holdings_table.update(delta)\n",
    "    \n",
    "quotes_view.on_update(update_holdings, mode=\"row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create another widget - here we want to see the last (latest) price for each symbol, sorted by price descending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f05576621044e6194ee030074c67c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PerspectiveWidget(aggregates={'price': 'last'}, columns=['price'], row_pivots=['symbol'], sort=[['price', 'des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quotes_widget = perspective.PerspectiveWidget(\n",
    "    quotes_table,\n",
    "    row_pivots=[\"symbol\"],\n",
    "    columns=[\"price\"],\n",
    "    aggregates={\"price\": \"last\"},\n",
    "    sort=[[\"price\", \"desc\"]])\n",
    "\n",
    "quotes_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting our datasource\n",
    "\n",
    "Now we can start the streaming datasource by providing it with a table and a function that returns data. Because `quote` is not implemented with Server-Sent Events (SSE), we want to manually poll the server every second—which works just as well for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the quotes to have the right format for sandbox data, which comes with randomly generated `time`s\n",
    "def clean_quote(tick):\n",
    "    for t in tick:\n",
    "        t[\"time\"] = datetime.now()\n",
    "    return tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = IEXIntervalDataSource(table=quotes_table, iex_source=client.last, data_cleaner=clean_quote, symbols=symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-09 11:41:58,646 [DataSource] Started\n",
      "2020-09-09 11:41:58,649 [IEXIntervalDataSource] started: fetching every 1 seconds\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 421, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 416, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\", line 1344, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\", line 306, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\", line 275, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/usr/local/lib/python3.7/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sandbox.iexapis.com', port=443): Max retries exceeded with url: /v1/tops/last?symbols=AAPL,MSFT,AMZN,TSLA,SPY,SNAP,ZM,JPM%2B&token=Tpk_ecc89ddf30a611e9958142010a80043c (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"datasources.ipynb\", line 54, in get_data\n",
      "    \"    def start(self):\\n\",\n",
      "  File \"datasources.ipynb\", line 53, in _get\n",
      "    \"        \\n\",\n",
      "  File \"datasources.ipynb\", line 53, in _get\n",
      "    \"        \\n\",\n",
      "  File \"datasources.ipynb\", line 53, in _get\n",
      "    \"        \\n\",\n",
      "  [Previous line repeated 24 more times]\n",
      "  File \"datasources.ipynb\", line 42, in _get\n",
      "    \"                be updated with new data.\\n\",\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyEX/client.py\", line 666, in bind\n",
      "    return meth(token=self._token, version=self._version, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyEX/marketdata/http.py\", line 62, in last\n",
      "    return _getJson('tops/last?symbols=' + ','.join(symbols) + '%2b', token, version)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyEX/common.py\", line 139, in _getJson\n",
      "    return _getJsonIEXCloudSandbox(url, token, version, filter)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyEX/common.py\", line 166, in _getJsonIEXCloudSandbox\n",
      "    resp = requests.get(urlparse(url).geturl(), proxies=_PYEX_PROXIES, params=params)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/requests/api.py\", line 75, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/requests/adapters.py\", line 510, in send\n",
      "    raise ProxyError(e, request=request)\n",
      "requests.exceptions.ProxyError: HTTPSConnectionPool(host='sandbox.iexapis.com', port=443): Max retries exceeded with url: /v1/tops/last?symbols=AAPL,MSFT,AMZN,TSLA,SPY,SNAP,ZM,JPM%2B&token=Tpk_ecc89ddf30a611e9958142010a80043c (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\n"
     ]
    }
   ],
   "source": [
    "# Start the subprocess and thread\n",
    "quotes.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-09 11:43:08,320 [DataSource] Stopped\n",
      "2020-09-09 11:43:08,322 [DataSource] Stopping update thread\n"
     ]
    }
   ],
   "source": [
    "# Stop the datasource from fetching more data, and dispose of the subprocess/thread\n",
    "quotes.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting\n",
    "\n",
    "Seeing live data is great, but what if we want to see how our portfolio has performed over time? By joining together Perspective tables, we can use IEX's [Historical Prices](https://iexcloud.io/docs/api/#historical-prices) endpoint to fetch historical data for backtesting. Then, we'll fetch our portfolio holdings from `holdings_table`, and join our holdings with the historical price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charts_schema conforms to the output of Historical Prices, with `quantity` added so we can easily join it with `holdings_table`.\n",
    "charts_table = perspective.Table(charts_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data cleaner function, we transform the chart data from the API to the correct format, and add our holdings for each symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_charts(tick):\n",
    "    out = []\n",
    "    for k, v in tick.items():\n",
    "        chart = v[\"chart\"]\n",
    "        for c in chart:\n",
    "            c[\"symbol\"] = k\n",
    "            c[\"quantity\"] = holdings[k]\n",
    "            out.append(c)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to poll the API for historical prices - getting everything in one shot is enough. Here, we'll get data for the last year (controlled by the `range_` kwarg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_: 1d, 1m, 1y, etc.\n",
    "charts = IEXStaticDataSource(charts_table, iex_source=client.batch, data_cleaner=clean_charts, symbols=symbols, fields=\"chart\", range_=\"1y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-09 11:42:11,902 [DataSource] Started\n"
     ]
    }
   ],
   "source": [
    "charts.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some more widgets - we can pass in the config as a dictionary, which allows us to switch quickly between widget configurations.\n",
    "\n",
    "- `ohlc_config` shows the Open, High, Low, and Close prices for `SPY`, which tracks the S&P 500 index. Changing the filter (or removing it entirely) will show exactly the symbols you want to see.\n",
    "- `value_config` computes the `value` column, which uses the quantity and each day's closing price to calculate the value of each symbol at the end of the day. This allows us to see the value of our portfolio split by symbol in the past year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohlc_config = {\n",
    "    \"plugin\": \"d3_ohlc\",\n",
    "    \"row_pivots\": [\"date\"],\n",
    "    \"columns\": [\"open\", \"close\", \"high\", \"low\"],\n",
    "    \"aggregates\": {\"quantity\": \"last\"},\n",
    "    \"filters\": [[\"symbol\", \"==\", \"SPY\"]]\n",
    "}\n",
    "\n",
    "value_config = {\n",
    "    \"plugin\": \"y_line\",\n",
    "    \"row_pivots\": [\"date\"],\n",
    "    \"column_pivots\": [\"symbol\"],\n",
    "    \"columns\": [\"value\"],\n",
    "    \"aggregates\": {\"quantity\": \"last\"},\n",
    "    \"computed_columns\": [{\n",
    "        \"column\": \"value\", \n",
    "        \"computed_function_name\": \"*\",\n",
    "        \"inputs\": [\"quantity\", \"close\"]\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af190f5228db40438c48255766fbc0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PerspectiveWidget(aggregates={'quantity': 'last'}, column_pivots=['symbol'], columns=['value'], computed_colum…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "charts_widget = perspective.PerspectiveWidget(\n",
    "    charts_table,\n",
    "    **value_config\n",
    ")\n",
    "charts_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to Apache Arrow\n",
    "\n",
    "Now we have our portfolio tables set up, how would we archive the value of our portfolio over time? One way is to write to [Apache Arrow](https://arrow.apache.org/), a storage format for columnar data that is lightning-fast to read and write.\n",
    "\n",
    "We can set up a separate thread that calls the view's `to_arrow()` method every 60 seconds, and dump the current state of the holdings total table every minute. Using the `minute_bucket` computed column, we can bucket the price updates into minutes instead of keeping data from each second. With row and column pivots on `minute_bucket` and `symbol`, we can show the value of the portfolio split across each symbol for every minute. This allows us to persist data beyond the life-cycle of the notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_holdings_view = holdings_total_table.view(\n",
    "    aggregates={\n",
    "        \"value\": \"last\",\n",
    "        \"quantity\": \"last\"\n",
    "    },\n",
    "    column_pivots=[\"symbol\"],\n",
    "    row_pivots=[\"minute_bucket\"],\n",
    "    columns=[\"symbol\", \"quantity\", \"value\", \"time\"],\n",
    "    computed_columns=[\n",
    "        {\n",
    "            \"column\": \"value\", \n",
    "            \"computed_function_name\": \"*\",\n",
    "            \"inputs\": [\"quantity\", \"price\"]\n",
    "        },\n",
    "        {\n",
    "            \"column\": \"minute_bucket\",\n",
    "            \"computed_function_name\": \"minute_bucket\",\n",
    "            \"inputs\": [\"time\"]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "stop_save = False\n",
    "\n",
    "async def _save():\n",
    "    while True:\n",
    "        if stop_save:\n",
    "            return\n",
    "\n",
    "        name = \"portfolio_value_{0:%Y_%m_%d}.arrow\".format(datetime.today())\n",
    "\n",
    "        if save_holdings_view.num_rows() > 0:\n",
    "            with open(name, \"wb\") as value_arrow:\n",
    "                value_arrow.write(save_holdings_view.to_arrow())\n",
    "            logging.info(\"Saved %d rows to %s\", holdings_total_table.size(), name)\n",
    "        await asyncio.sleep(60)\n",
    "\n",
    "def save_to_arrow():\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    task = loop.create_task(_save())\n",
    "    loop.run_until_complete(task)\n",
    "    \n",
    "save_thread = threading.Thread(target=save_to_arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_thread' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4fe647aabb83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_thread' is not defined"
     ]
    }
   ],
   "source": [
    "save_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"portfolio_value_{0:%Y_%m_%d}.arrow\".format(datetime.today()), \"rb\") as arr:\n",
    "    w = perspective.PerspectiveWidget(arr.read(), sort=[[\"time\", \"desc\"]])\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remember to mention that all this code can be modularized and run as a tornado server for perspective in the browser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
